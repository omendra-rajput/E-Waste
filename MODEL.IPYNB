{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# E-Waste Management System using CNN\n",
    "# This script generates synthetic e-waste data, trains a CNN to classify items based on images, and filters records for analysis.\n",
    "# Tools: TensorFlow, Pandas, NumPy, Matplotlib, Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import ast\n",
    "import sys\n",
    "import argparse\n",
    "import gc\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Generate Mock Data\n",
    "# Simulates e-waste items with image data and metadata.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def generate_mock_data(sample_size=5000):\n",
    "    try:\n",
    "        categories = ['Computers', 'Mobiles', 'Batteries', 'Printers', 'Monitors',\n",
    "                      'TVs', 'Cables', 'Scanners', 'Servers', 'Others']\n",
    "        item_types = ['Laptop', 'Battery', 'Printer', 'Cable', 'Scanner', 'TV', 'Mobile']\n",
    "        conditions = ['Working', 'Dead']\n",
    "        sectors = ['IT', 'Telecom', 'Retail', 'Healthcare', 'Education', 'Manufacturing']\n",
    "\n",
    "        data = []\n",
    "        for _ in range(sample_size):\n",
    "            data.append({\n",
    "                \"Item_Type\": random.choice(item_types),\n",
    "                \"Weight(kg)\": round(random.uniform(0.1, 20.0), 2),\n",
    "                \"Condition\": random.choice(conditions),\n",
    "                \"Sector\": random.choice(sectors),\n",
    "                \"Category\": random.choice(categories),\n",
    "                \"Image_Data\": np.random.rand(32, 32, 3).tolist()\n",
    "            })\n",
    "\n",
    "        df = pd.DataFrame(data)\n",
    "        df.to_csv('e_waste_dataset.csv', index=False)\n",
    "        print(f\"Mock dataset created with {sample_size} records.\")\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"Error during data generation: {e}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Train CNN Model\n",
    "# Prepares image data, builds a CNN, and evaluates performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_cnn_model(df, epochs=10):\n",
    "    try:\n",
    "        print(\"Preparing image data for training...\")\n",
    "        X = []\n",
    "        for idx, img in enumerate(df['Image_Data']):\n",
    "            try:\n",
    "                X.append(np.array(ast.literal_eval(str(img))))\n",
    "            except Exception as e:\n",
    "                print(f\"Failed to parse image at index {idx}: {e}\")\n",
    "                return None, 0\n",
    "        X = np.array(X)\n",
    "        if X.size == 0:\n",
    "            print(\"Image data could not be processed.\")\n",
    "            return None, 0\n",
    "        le = LabelEncoder()\n",
    "        y = le.fit_transform(df['Category'])\n",
    "        y = to_categorical(y, num_classes=10)\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "        model = Sequential([\n",
    "            Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)),\n",
    "            MaxPooling2D((2, 2)),\n",
    "            Conv2D(64, (3, 3), activation='relu'),\n",
    "            MaxPooling2D((2, 2)),\n",
    "            Flatten(),\n",
    "            Dense(128, activation='relu'),\n",
    "            Dropout(0.5),\n",
    "            Dense(10, activation='softmax')\n",
    "        ])\n",
    "        model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "        early_stop = EarlyStopping(monitor='val_loss', patience=3)\n",
    "        print(\"Training CNN model...\")\n",
    "        history = model.fit(\n",
    "            X_train, y_train,\n",
    "            epochs=epochs,\n",
    "            batch_size=32,\n",
    "            validation_split=0.2,\n",
    "            callbacks=[early_stop],\n",
    "            verbose=1\n",
    "        )\n",
    "        # Plot training progress\n",
    "        plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "        plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "        plt.title('Model Training Performance')\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('Accuracy')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.savefig(\"training_accuracy.png\")\n",
    "        plt.close()\n",
    "        print(\"Training accuracy graph saved as 'training_accuracy.png'.\")\n",
    "\n",
    "        loss, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "        print(f\"Model training completed. Test Accuracy: {accuracy:.4f}\")\n",
    "        if accuracy >= 0.92:\n",
    "            print(\"Target accuracy of 92% achieved.\")\n",
    "        else:\n",
    "            print(\"Model did not reach target accuracy. Consider further tuning.\")\n",
    "\n",
    "        model.save('e_waste_cnn_classifier.h5')\n",
    "        print(\"Model saved as 'e_waste_cnn_classifier.h5'.\")\n",
    "\n",
    "        del X_train, X_test, y_train, y_test\n",
    "        gc.collect()\n",
    "\n",
    "        return model, accuracy\n",
    "    except Exception as e:\n",
    "        print(f\"Error during model training: {e}\")\n",
    "        return None, 0\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Step 3: Filter and Export Data\n",
    "# Filters non-working items above 1kg and exports them for visualization.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_data(df):\n",
    "    try:\n",
    "        filtered_df = df[(df['Condition'] == 'Dead') & (df['Weight(kg)'] > 1.0)]\n",
    "        sector_counts = filtered_df.groupby('Sector').size().reset_index(name='Count')\n",
    "\n",
    "        print(\"\\nSector-wise breakdown of dead and heavy e-waste:\")\n",
    "        print(sector_counts)\n",
    "\n",
    "        filtered_df.drop(columns=['Image_Data']).to_csv('filtered_data.csv', index=False)\n",
    "        print(\"Filtered data saved to 'filtered_data.csv'.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error during data filtering: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Main Runner\n",
    "# This block ties everything together using command-line arguments.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser(description=\"E-Waste Management System\")\n",
    "    parser.add_argument('--samples', type=int, default=5000, help='Number of mock records to generate')\n",
    "    parser.add_argument('--epochs', type=int, default=10, help='Epochs for training the CNN model')\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    print(\"\\nStarting E-Waste Management System...\\n\")\n",
    "\n",
    "    if sys.version_info < (3, 7):\n",
    "        print(\"This script requires Python 3.7 or higher.\")\n",
    "        sys.exit(1)\n",
    "\n",
    "    df = generate_mock_data(sample_size=args.samples)\n",
    "    if df is None:\n",
    "        print(\"Data generation failed. Exiting.\")\n",
    "        sys.exit(1)\n",
    "\n",
    "    model, accuracy = train_cnn_model(df, epochs=args.epochs)\n",
    "    if model is None:\n",
    "        print(\"Model training failed. Exiting.\")\n",
    "        sys.exit(1)\n",
    "\n",
    "    filter_data(df)\n",
    "\n",
    "    print(\"\\nExecution complete.\")\n",
    "    print(\"Next steps:\")\n",
    "    print(\"- Open 'filtered_data.csv' in Tableau or Excel for analysis.\")\n",
    "    print(\"- Review 'training_accuracy.png' for model performance.\")\n",
    "    print(\"- Use 'e_waste_cnn_classifier.h5' to run predictions on new images.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
